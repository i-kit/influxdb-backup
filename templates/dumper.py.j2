#!/usr/bin/env python

'''
Description:  Script to backup influxdb and save to s3
Dependency:   Boto, installed via apt-get install python-boto
Author:       Ivan Kit (based on old version of Evan Richardson)
Date:         08-19-2021
Version:      2.0 (updated for usage with InfluxDB v2 OSS)
'''

import argparse
import boto3
import os
import glob
import tarfile
import time
import sys
import shutil
from subprocess import call
from dateutil import tz

# some variables we'll use
BACKUP_PATH = '{{backup_path}}'
BACKUP_TIME = str(int(time.time()))
BACKUP_BUCKET = '{{backup_backet}}'
ACCESS_KEY_ID = '{{access_key_id}}'
SECRET_KEY = '{{secret_key}}'
UPLOAD_FOLDER = '{{upload_folder}}'
TOKEN = '{{ influxdb_token }}'
CLIENT = boto3.client(
    's3',
    aws_access_key_id=ACCESS_KEY_ID,
    aws_secret_access_key=SECRET_KEY,
)


class ProgressPercentage(object):

    def __init__(self, filename):
        self._filename = filename
        self._size = float(os.path.getsize(filename))
        self._seen_so_far = 0
        self._lock = threading.Lock()

    def __call__(self, bytes_amount):
        # To simplify, assume this is hooked up to a single filename
        with self._lock:
            self._seen_so_far += bytes_amount
            percentage = (self._seen_so_far / self._size) * 100
            sys.stdout.write(
                "\r%s  %s / %s  (%.2f%%)" % (
                    self._filename, self._seen_so_far, self._size,
                    percentage))
            sys.stdout.flush()


def backup(database_name):

    # backup
    call(["influx", "backup", "-b", database_name, BACKUP_PATH, "-t", TOKEN])

    tar = tarfile.open(BACKUP_PATH + database_name + '_'
                       + BACKUP_TIME + '.tar.gz', "w:gz")
    for name in glob.glob(BACKUP_PATH):
        tar.add(name, arcname=os.path.basename(name))
    tar.close()

    # upload backup
    archive_path = max(glob.iglob(BACKUP_PATH + '*.gz'), key=os.path.getctime)
    archive_name = os.path.basename(archive_path)
    CLIENT.upload_file(archive_path, BACKUP_BUCKET, UPLOAD_FOLDER + '/'
                       + archive_name, Callback=ProgressPercentage(archive_path))

    # cleanup
    files = glob.glob(BACKUP_PATH + '*')
    for file_name in files:
        os.remove(file_name)
    return


def restore(backup_to_restore, download_path, database_name):
    print("Downloading restore point: %s" % backup_to_restore)

    if not os.path.exists(download_path + "/" + database_name):
        os.makedirs(download_path + "/" + database_name)

    CLIENT.download_file(BACKUP_BUCKET, '%s/%s' % (UPLOAD_FOLDER, backup_to_restore), download_path + '/'
                         + 'InfluxRestore.tar.gz')

    print(download_path)
    print("Extracting Archive...")
    os.chdir(download_path)
    tar = tarfile.open('InfluxRestore.tar.gz')
    tar.extractall()
    tar.close()

    print("Restoring backup from %s" % download_path)
    call(["influx", "restore", "--bucket", database_name, download_path, "-t", TOKEN])

    # remove restore folder and contents
    shutil.rmtree(download_path)
    return


def restorepoints():
    to_zone = tz.gettz('America/Los_Angeles')
    objects = CLIENT.list_objects(Bucket=BACKUP_BUCKET, Prefix='%s/' % UPLOAD_FOLDER)

    for item in objects['Contents']:
        print(item['LastModified'].astimezone(to_zone).strftime('%Y-%m-%d_%H%M%S %Z') + " " + item['Key'])
    return


def main(argv):

    parser = argparse.ArgumentParser(description='Script to backup or restore' +
                                     'InfluxDB backups to/from AWS S3.')
    parser.add_argument('-b', '--backup', type=str,
                        help='Backup a given Database')
    parser.add_argument('-p', '--path', type=str, default='/tmp/influxdb',
                        help='Location of for Database Backups')
    parser.add_argument('-r', '--restore', type=str,
                        help='Restore a backup from S3')
    parser.add_argument('-db', '--databasename', type=str,
                        help='DB name to restore from backup')
    parser.add_argument('-rp', '--restorepoints', action='store_true',
                        help='Get a list of available backups from S3')
    args = parser.parse_args()

    if args.backup is not None and args.restore is None:
        print("backup has been set to %s" % args.backup)
        print("destination has been set to %s" % args.path)
        backup(args.backup)

    if args.restore is not None and args.backup is None:
        download_path = args.path + "/" + args.databasename
        if not os.path.exists(download_path):
            print("Restore path %s does not exist, creating..." % download_path)
            os.makedirs(download_path)

        print("Downloading and Restoring %s from S3" % args.restore)
        restore(args.restore, download_path, args.databasename)

    if args.backup is not None and args.restore is not None:
        print("You cannot backup and restore at the same time!")

    if args.backup is None and args.restore is None and args.restorepoints is not None:
        restorepoints()


if __name__ == "__main__":
    main(sys.argv[1:])

